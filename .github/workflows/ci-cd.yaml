name: Flight Booking CICD

on:
  push:
    branches:
      - dev
  pull_request:
    branches:
      - main

jobs:
  upload-to-dev:
    if: github.ref == 'refs/heads/dev'
    runs-on: ubuntu-latest

    steps:
      # Checkout the repository
      - name: Checkout Code
        uses: actions/checkout@v3

      # Install Google Cloud SDK
      - name: Setup Google Cloud SDK
        uses: google-github-actions/setup-gcloud@v1
        with:
          service_account_key: ${{ secrets.GCP_SA_KEY }}
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      # Sync variables to Airflow DEV Composer
      - name: Upload Variables to Airflow-DEV
        run: |
          gcloud composer environments storage data import \
            --environment airflow-dev \
            --location us-central1 \
            --source variables/dev

      # Sync Spark job to GCS
      - name: Upload Spark Job to GCS
        run: |
          gsutil cp spark_job/spark_transformation_job.py gs://airflow-projetcs-gds/airflow-project-1/spark-job/

      # Sync Airflow DAG to Airflow DEV Composer
      - name: Upload Airflow Test DAG to DEV
        run: |
          gcloud composer environments storage dags import \
            --environment airflow-dev \
            --location us-central1 \
            --source airflow_job/airflow_test.py

  upload-to-prod:
    if: github.event_name == 'pull_request' && github.event.pull_request.merged == true
    runs-on: ubuntu-latest

    steps:
      # Checkout the repository
      - name: Checkout Code
        uses: actions/checkout@v3

      # Install Google Cloud SDK
      - name: Setup Google Cloud SDK
        uses: google-github-actions/setup-gcloud@v1
        with:
          service_account_key: ${{ secrets.GCP_SA_KEY }}
          project_id: ${{ secrets.GCP_PROJECT_ID }}

      # Sync variables to Airflow PROD Composer
      - name: Upload Variables to Airflow-PROD
        run: |
          gcloud composer environments storage data import \
            --environment airflow-prod \
            --location us-central1 \
            --source variables/prod

      # Sync Spark job to GCS
      - name: Upload Spark Job to GCS
        run: |
          gsutil cp spark_job/spark_transformation_job.py gs://airflow-projetcs-gds/airflow-project-1/spark-job/

      # Sync Airflow DAG to Airflow PROD Composer
      - name: Upload Airflow Test DAG to PROD
        run: |
          gcloud composer environments storage dags import \
            --environment airflow-prod \
            --location us-central1 \
            --source airflow_job/airflow_test.py